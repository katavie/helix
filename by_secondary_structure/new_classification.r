library(dplyr)
library(caret)
library(boot)
library(ROCR)
library(plotROC)
library(ggplot2)
library(plotly)
library(corrplot)

### QUICK START
setwd('C:/Users/Jan_Huang/Desktop/helix_grindtime/by_secondary_structure')
data <- read.csv('data_full.csv')
data <- subset(data, select=c('seq', 'code', 'disp', 'GC', 'ss', 'maxORF', 'ORFcover', 'maxnstop'))
data$code <- as.factor(data$code)

# make results reproducible
set.seed(500)

### INITIAL DATASET CLEANING
# filtering by length is done in Python
# make datasets the same size by randomly choosing sequences from bigger dataset
fraction <- nrow(coding) / nrow(noncoding)
nc_index <- sample(x = 1:nrow(noncoding), size = round(fraction * nrow(noncoding)))
noncoding <- noncoding[nc_index, ]
# remove duplicate sequences
data <- data[!duplicated(data$seq), ]

### FEATURE EXTRACTION
# values imported from files generated by Python algorithms
disp <- as.matrix(read.csv('data_full_disp.csv'))
for (i in 1:nrow(disp)) {
  data$disp[i] <- disp[i]
}
GC <- as.matrix(read.csv('data_full_GC.csv'))
for (i in 1:nrow(GC)) {
  data$GC[i] <- GC[i]
}
maxORF <- as.matrix(read.csv('data_full_maxORF.csv'))
for (i in 1:nrow(maxORF)) {
  data$maxORF[i] <- maxORF[i]
}
ORFcover<- as.matrix(read.csv('data_full_ORFcover.csv'))
for (i in 1:nrow(ORFcover)) {
  data$ORFcover[i] <- ORFcover[i]
}
maxNStop <- as.matrix(read.csv('data_full_maxNStop.csv'))
for (i in 1:nrow(maxNStop)) {
  data$maxnstop[i] <- maxNStop[i]
}
write.csv(data, 'data_full.csv')

### DESCRIPTIVE STATISTICS FOR FEATURES

# compare sequence lengths
for (i in 1:nrow(coding)) {
  coding$length[i] <- nchar(as.character(coding$seq[i]))
}
for (i in 1:nrow(noncoding)) {
  noncoding$length[i] <- nchar(as.character(noncoding$seq[i]))
}

hist(coding$length, main='Length of Coding Sequences', xlim=c(0, 100000), breaks=100, xlab='Length')
hist(noncoding$length, main='Length of Noncoding Sequences', xlim=c(0, 100000), breaks=100, xlab='Length')

# correlation matrix
feature_cols <- c(3,4,6,7,8)
M <- cor(data[feature_cols])
corrplot(M, type='upper', method='color', tl.col='black', tl.srt=45, addCoef.col='black', diag=FALSE, mar=c(0,0,1,0))

mean(data[data$code == '1', ]$GC) # 51.86%
mean(data[data$code == '0', ]$GC) # 46.49%
sd(data[data$code == '1', ]$GC) # 7.93%
sd(data[data$code == '0', ]$GC) # 12.02%

mean(data[data$code == '1', ]$disp) # .73
mean(data[data$code == '0', ]$disp) # .61
sd(data[data$code == '1', ]$disp) # .11
sd(data[data$code == '0', ]$disp) # .13

mean(data[data$code == '1', ]$maxORF) # 439.11
mean(data[data$code == '0', ]$maxORF) # 221.08
sd(data[data$code == '1', ]$maxORF) # 394.13
sd(data[data$code == '0', ]$maxORF) # 230.42

shapiro.test(data[data$code=='1',]$GC) # not normal; p=1.028e-07
shapiro.test(data[data$code=='0',]$GC) # not normal; p=6.503e-05
shapiro.test(data[data$code=='1',]$disp) # not normal; p=2.241e-07
shapiro.test(data[data$code=='0',]$disp) # not normal; p=2.2e-16
# conclusion: reject null that distributions are normal

fligner.test(data[data$code=='1',]$GC, data[data$code=='0',]$GC) # p=.405, variances are same
fligner.test(data[data$code=='1',]$disp, data[data$code=='0',]$disp) # p=.492, variances are same
# conclusion: variances are same

# Wilcoxon Rank Sum Test (compare mean of 2 samples)
# alternative: true location shift is not equal to 0
wilcox.test(data[data$code=='1',]$GC, data[data$code=='0',]$GC) # p=9.46e-14
wilcox.test(data[data$code=='1',]$disp, data[data$code=='0',]$disp) # p=2.2e-16
# conclusion: from diff distributions

ggplot(data=data, aes(data$disp, fill=code)) + geom_histogram(binwidth = .05) + labs(title='Histogram of Median Disparity', x='Median Disparity', y='Count') + scale_fill_discrete(name = '', labels = c('Noncoding', 'Coding'))

# by SS!
ggplot(data=data, aes(x=data$disp, y=..density.., color=code, fill=ss)) +
  xlim(0.3,1.2) +
  scale_fill_discrete(name = 'Secondary Structure', breaks = c('', 'a', 'ab', 'b', 'fSS'), labels = c('Noncoding', 'Mainly Alpha', 'Alpha Beta', 'Mainly Beta', 'Few Secondary Structures')) +
  labs(title='Median Disparity by Secondary Structure', x='Median Disparity', y='Density') +
  geom_density(alpha=0.1)

ggplot(data=data, aes(x=data$GC, y=..density.., color=code, fill=code)) +
  scale_fill_discrete(name = '', labels = c('Noncoding', 'Coding')) +
  labs(title='GC Percentage vs Coding Status', x='GC%', y='Density') +
  geom_density(alpha=0.1)

plot_ly(data=data, x=~GC, y=~disp, z=~maxORF, color=~code)

ggplot(data=data, aes(x=data$disp, y=..density.., color=ss, fill=ss)) + labs(title='Median Disparity', x='Median Disparity', y='Density') + geom_density(position='fill')

ggplot(data=data, aes(data$GC, fill=code)) + geom_histogram(binwidth = 1.15) + labs(title='Histogram of GC Percentage', x='GC Percentage', y='Count') + scale_fill_discrete(name = '', labels = c('Noncoding', 'Coding'))

ggplot(data=data, aes(data$maxORF, fill=code)) + geom_histogram() + labs(title='Histogram of Max ORF Length', x='Max ORF Length', y='Count') + scale_fill_discrete(name = '', labels = c('Noncoding', 'Coding'))

# visualize correlations btwn/among features
ggplot(data=data, aes(x=data$GC, y=data$disp)) + geom_point(aes(GC, disp, color=code)) + labs(title='Scatterplot of GC Percentage vs Median Disparity')

ggplot(data=data, aes(x=data$maxORF, y=data$disp)) + geom_point(aes(GC, disp, color=code)) + labs(title='Scatterplot')

### 75/25 TRAIN/TEST PROPORTIONAL SPLIT

# proportional split
train_indices_a <- sample(x = as.vector(which(data$ss=='a')), size = round(0.75 * nrow(data[data$ss=='a', ])))
train_indices_b <- sample(x = as.vector(which(data$ss=='b')), size = round(0.75 * nrow(data[data$ss=='b', ])))
train_indices_ab <- sample(x = as.vector(which(data$ss=='ab')), size = round(0.75 * nrow(data[data$ss=='ab', ])))
train_indices_fSS <- sample(x = as.vector(which(data$ss=='fSS')), size = round(0.75 * nrow(data[data$ss=='fSS', ])))
train_indices_nc <- sample(x = as.vector(which(data$code==0)), size = round(0.75 * nrow(data[data$code==0, ])))

train_indices_all <- c(train_indices_a, train_indices_b, train_indices_ab, train_indices_fSS, train_indices_nc)
train <- data[train_indices_all,]
test <- data[-train_indices_all,]

# save just in case :)
write.csv(train, 'data_train_proportional.csv')
write.csv(test, 'data_test_proportional.csv')

### LOGISTIC REGRESSION

# control: standard features only (i.e. no disparity)
control_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
summary(control_p)
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#0.0011  0.3177  0.4587  0.5026  0.6838  1.0000
control_p_class <- ifelse(control_p > .50, 1, 0)
confusionMatrix(control_p_class, test[['code']])
#          Reference
#Prediction   0   1
#         0 845 400
#         1 281 727
# Accuracy: 69.77
# Sensitivity: 75.04
# Specificity: 64.51

# experimental: standard features + disparity
exp_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp, family = 'binomial', train)
exp_p <- predict(exp_model, test, type = 'response')
summary(exp_p)
#     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
#0.0002476 0.2365053 0.4744746 0.5055679 0.7822746 1.0000000
exp_p_class <- ifelse(exp_p > .50, 1, 0)
confusionMatrix(exp_p_class, test[['code']])
#          Reference
#Prediction   0   1
#         0 920 255
#         1 206 872
# Accuracy: 79.54
# Sensitivity: 81.71
# Specificity: 77.37

### ROC CURVE
control_pred <- prediction(control_p, test$code)
control_sens <- performance(control_pred, measure='sens', x.measure='cutoff') # true positive rate
control_spec <- performance(control_pred, measure='spec', x.measure='cutoff') # true negative rate
plot(control_sens, main='Sensitivity and Specificity vs Cutoff', col='red', ylab='Sensitivity/Specificity')
plot(control_spec, add=TRUE, col='blue')
# work out geom_roc later

### RANK FEATURES BY IMPORTANCE
# if feature less important than random noise, then it's not significant
# uses learning vector quantization (LVQ)
(control_varImp <- varImp(control_model, scale=FALSE))
#GC       10.77046
#maxORF   18.14501
#ORFcover 17.09556
#maxnstop 12.15270
(exp_varImp <- varImp(exp_model, scale=FALSE))
#GC       14.37687
#maxORF   18.38776
#ORFcover 14.77688
#maxnstop 11.09030
#disp     27.99592

### CROSS VALIDATION
# 10-fold cV on control, using Bayes GLM
(control_cv <- train(
  code ~ GC + maxORF + ORFcover + maxnstop, data,
  method = 'bayesglm',
  trControl = trainControl(
    method = 'cv', number = 10,
    verboseIter = TRUE
  )
))
# accuracy: 70.52
# kappa: 41.04 - borderline poor
# Kappa = (observed accuracy - expected accuracy)/(1 - expected accuracy)

# 10-fold cV on control, using Bayes GLM
(exp_cv <- train(
  code ~ GC + maxORF + ORFcover + maxnstop + disp, data,
  method = 'bayesglm',
  trControl = trainControl(
    method = 'cv', number = 10,
    verboseIter = TRUE
  )
))
# accuracy: 79.00
# kappa: 58.01 - moderate/good

### ANOVA
# all features add significant improvement to the model