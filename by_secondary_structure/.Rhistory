library(caret)
setwd('C:/Users/Jan_Huang/Desktop/helix_grindtime/by_secondary_structure')
data <- read.csv('data_full.csv')
data <- subset(data, select=c('seq', 'code', 'disp', 'GC', 'ss', 'maxORF', 'ORFcover', 'maxnstop'))
data$code <- as.factor(data$code)
train_indices_a <- sample(x = as.vector(which(data$ss=='a')), size = round(0.75 * nrow(data[data$ss=='a', ])))
train_indices_b <- sample(x = as.vector(which(data$ss=='b')), size = round(0.75 * nrow(data[data$ss=='b', ])))
train_indices_ab <- sample(x = as.vector(which(data$ss=='ab')), size = round(0.75 * nrow(data[data$ss=='ab', ])))
train_indices_fSS <- sample(x = as.vector(which(data$ss=='fSS')), size = round(0.75 * nrow(data[data$ss=='fSS', ])))
train_indices_nc <- sample(x = as.vector(which(data$code==0)), size = round(0.75 * nrow(data[data$code==0, ])))
train_indices_all <- c(train_indices_a, train_indices_b, train_indices_ab, train_indices_fSS, train_indices_nc)
train <- data[train_indices_all,]
test <- data[-train_indices_all,]
control_model <- glm(code ~ GC + maxORF + ORFcover, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
summary(p)
summary(control_p)
control_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
summary(control_p)
control_p_class <- ifelse(p > .50, 1, 0)
confusionMatrix(control_p_class, test[['code']])
control_p <- predict(control_model, test, type = 'response')
summary(control_p)
control_p_class <- ifelse(control_p > .50, 1, 0)
confusionMatrix(control_p_class, test[['code']])
?anova
?extraSS
anova(control_model)
anova(control_model, exp_model)
exp_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp, family = 'binomial', train)
exp_p <- predict(exp_model, test, type = 'response')
summary(exp_p)
exp_p_class <- ifelse(p > .50, 1, 0)
confusionMatrix(exp_p_class, test[['code']])
exp_p_class <- ifelse(p > .50, 1, 0)
exp_p_class <- ifelse(exp_p > .50, 1, 0)
confusionMatrix(exp_p_class, test[['code']])
anova(control_model, exp_model)
shapiro.test(control_p)
shapiro.test(exp_p)
var.test()
var.test(control_p, exp_p)
var.test(control_p, exp_p)$p.value
anova(control_model, exp_model)
anova(control_model)
anova(control_model)$p.value
?lrtest
anova(control_model, test='Chisq')
anova(control_model, exp_model, test='Chisq')
anova(control_model, test='Chisq')
anova(cexp_model, test='Chisq')
anova(exp_model, test='Chisq')
anova(exp_model, test='Chisq')$p.value
anova(exp_model, test='Chisq')[0]
anova(exp_model, test='Chisq')$GC
anova(exp_model)
anova(control_model)
anova(control_model)$p.value
?anova
print(anova(control_model))
coef(control_model)
summary(anova(control_model))
summary(anova(control_model, exp_model))
anova(control_model, exp_model)
?aov
summary(aov(code~disp))
summary(aov(code~disp, data=data))
summary(aov(code~GC, data=data))
summary(aov(disp~code, data=data))
anova(control_model, test = 'Chisq')
anova(control_model, test = 'Chisq')"Pr(>Chi)"
anova(control_model, test = 'Chisq')[[Pr(>Chi)]]
summary(control_model)
summary(exp_model)
?varImp
(control_varImp <- varImp(control, scale=FALSE))
(control_varImp <- varImp(control_model, scale=FALSE))
(exp_varImp <- varImp(exp_model, scale=FALSE))
(exp_varImp <- varImp(exp_model))
(exp_varImp <- varImp(exp_model, scale=TRUE))
(varImp(exp_model, scale=TRUE))
(exp_varImp <- varImp(exp_model, scale=FALSE))
(control_varImp <- varImp(control_model, scale=FALSE))
cv.glm(data = data, control_model, k = 10)
install.packages('boot')
library(boot)
cv.glm(data = data, control_model, k = 10)
cv.glm(data = data, control_model, K = 10)
control_cv <- cv.glm(data = data, control_model, K = 10)
summary(control_cv)
control_cv
?train
control_cv$delta
control_cv <- cv.glm(data = data, control_model, K = 10)
control_cv$delta
control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop, train,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv
control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop, train,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv
control_cv <- cv.glm(data = data, control_model, K = 10)
control_cv
control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop, data,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop, data
)
control_cv <- train(
code ~ GC + maxORF + ORFcover, data,
method = 'lm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv <- train(
code ~ GC + maxORF + ORFcover, data,
method = 'bayesglm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv
data[data$maxnstop=NA,]$maxnstop <- 0
data[data$maxnstop==NA,]$maxnstop <- 0
data[data$maxnstop=='',]$maxnstop <- 0
?is.na
data[is.na(data)]$maxnstop <- 0
data[is.na(data)] <- 0
nrow(data[data$ss==0])
nrow(data[data$ss=='a'])
nrow(data[data$ss=='a',])
nrow(data[data$ss==0,])
nrow(data[data$maxnstop==0,])
control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop, data,
method = 'bayesglm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
)
control_cv
(exp_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop + disp, data,
method = 'bayesglm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
))
control_pred <- prediction(control_p, test$code)
library(ROCR)
control_pred <- prediction(control_p, test$code)
sens <- performance(control_pred, measure='sens', x.measure='cutoff') # true positive rate
control_sens <- performance(control_pred, measure='sens', x.measure='cutoff') # true positive rate
control_spec <- performance(control_pred, measure='spec', x.measure='cutoff') # true negative rate
plot(sens, main='Sensitivity and Specificity vs Cutoff', col='red', ylab='Sensitivity/Specificity')
plot(control_sens, main='Sensitivity and Specificity vs Cutoff', col='red', ylab='Sensitivity/Specificity')
plot(control_spec, add=TRUE, col='blue')
best.sum <- which.max(control_sens@y.values[[1]]+control_spec@y.values[[1]])
control_sens@x.values[[1]][best.sum]
control_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
summary(control_p)
control_p_class <- ifelse(control_p > .4176, 1, 0)
confusionMatrix(control_p_class, test[['code']])
exp_pred <- prediction(exp_p, test$code)
exp_sens <- performance(exp_pred, measure='sens', x.measure='cutoff') # true positive rate
exp_spec <- performance(exp_pred, measure='spec', x.measure='cutoff') # true negative rate
plot(exp_sens, main='Experimental Model: Sensitivity and Specificity vs Cutoff', col='red', ylab='Sensitivity/Specificity')
plot(exp_spec, add=TRUE, col='blue')
best.sum <- which.max(exp_sens@y.values[[1]]+exp_spec@y.values[[1]])
exp_sens@x.values[[1]][best.sum] # 41.76
exp_best.sum <- which.max(exp_sens@y.values[[1]]+exp_spec@y.values[[1]])
exp_sens@x.values[[1]][exp_best.sum] # 41.76
exp_pred <- prediction(exp_p, test$code)
exp_sens <- performance(exp_pred, measure='sens', x.measure='cutoff') # true positive rate
exp_spec <- performance(exp_pred, measure='spec', x.measure='cutoff') # true negative rate
plot(exp_sens, main='Experimental Model: Sensitivity and Specificity vs Cutoff', col='red', ylab='Sensitivity/Specificity')
plot(exp_spec, add=TRUE, col='blue')
both.eq <- which.min(abs(exp_sens@y.values[[1]]-exp_spec@y.values[[1]]))
exp_sens@x.values[[1]][both.eq]
control_best.sum <- which.max(control_sens@y.values[[1]]+control_spec@y.values[[1]])
control_sens@x.values[[1]][control_best.sum] # 41.76
control_both.eq <- which.min(abs(control_sens@y.values[[1]]-control_spec@y.values[[1]]))
control_sens@x.values[[1]][control_both.eq] # 46.99
control_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
summary(control_p)
control_p_class <- ifelse(control_p > .4587, 1, 0)
confusionMatrix(control_p_class, test[['code']])
exp_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp, family = 'binomial', train)
exp_p <- predict(exp_model, test, type = 'response')
exp_p_class <- ifelse(exp_p > .3965, 1, 0)
confusionMatrix(exp_p_class, test[['code']])
exp_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp, family = 'binomial', train)
exp_p <- predict(exp_model, test, type = 'response')
exp_p_class <- ifelse(exp_p > .4176, 1, 0)
confusionMatrix(exp_p_class, test[['code']])
exp_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp, family = 'binomial', train)
exp_p <- predict(exp_model, test, type = 'response')
exp_p_class <- ifelse(exp_p > .5, 1, 0)
confusionMatrix(exp_p_class, test[['code']])
control_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
control_p_class <- ifelse(control_p > .5, 1, 0)
confusionMatrix(control_p_class, test[['code']])
control_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop, family = 'binomial', train)
control_p <- predict(control_model, test, type = 'response')
control_p_class <- ifelse(control_p > .4176, 1, 0)
confusionMatrix(control_p_class, test[['code']])
?which.max
?train
(exp_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop + disp, data,
method = 'glm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
))
(control_cv <- train(
code ~ GC + maxORF + ORFcover + maxnstop, data,
method = 'glm',
trControl = trainControl(
method = 'cv', number = 10,
verboseIter = TRUE
)
))
randnums <- sample(x=1:nrow(train), size=nrow(train))
for (i in nrow(train)) {
train$randnum[i] <- randnums[i]
}
noise_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp + randnum, family = 'binomial', train)
noise_p <- predict(noise_model, test, type = 'response')
noise_pred <- prediction(noise_p, test$code)
noise_p <- predict(noise_model, test, type = 'response')
View(train)
for (i in nrow(train)) {
train$randnum[i] <- randnums[i]
}
for (i in 1:nrow(train)) {
train$randnum[i] <- randnums[i]
}
boxplot(train$randnum)
boxplot(train[train$code==0,]$randnum)
boxplot(train[train$code==1,]$randnum)
shapiro.test(train$randnum)
shapiro.test(train$randnum[1:5000,])
shapiro.test(train$randnum[1:5000])
noise_sens <- performance(noise_pred, measure='sens', x.measure='cutoff') # true positive rate
noise_pred <- prediction(noise_p, test$code)
noise_sens <- performance(noise_pred, measure='sens', x.measure='cutoff') # true positive rate
noise_pred <- prediction(noise_p, test$code)
noise_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp + randnum, family = 'binomial', train)
noise_p <- predict(noise_model, test, type = 'response')
noise_pred <- prediction(noise_p, test$code)
noise_p <- predict(noise_model, test, type = 'response')
noise_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp + randnum, family = 'binomial', data=train)
noise_p <- predict(noise_model, test, type = 'response')
randnums <- sample(x=1:nrow(data), size=nrow(data))
for (i in 1:nrow(train)) {
train$randnum[i] <- randnums[i]
}
for (i in 1:nrow(test)) {
test$randnum[i] <- randnums[i+nrow(train)]
}
noise_model <- glm(code ~ GC + maxORF + ORFcover + maxnstop + disp + randnum, family = 'binomial', data=train)
noise_p <- predict(noise_model, test, type = 'response')
noise_pred <- prediction(noise_p, test$code)
noise_sens <- performance(noise_pred, measure='sens', x.measure='cutoff') # true positive rate
noise_spec <- performance(noise_pred, measure='spec', x.measure='cutoff') # true negative rate
noise_best.sum <- which.max(noise_sens@y.values[[1]]+noise_spec@y.values[[1]])
noise_sens@x.values[[1]][exp_best.sum] # 39.65
noise_p_class <- ifelse(noise_p > .3993, 1, 0)
confusionMatrix(noise_p_class, test[['code']])
(noise_varImp <- varImp(noise_model, scale=FALSE))
anova(control_model, exp_model)
anova(control_model, exp_model, test='Chisq')
corrplot(M, type='upper', method='color', tl.col='black', tl.srt=45, addCoef.col='black', diag=FALSE, mar=c(0,0,1,0))
library(corrplot)
feature_cols <- c(3,4,6,7,8)
M <- cor(data[feature_cols])
corrplot(M, type='upper', method='color', tl.col='black', tl.srt=45, addCoef.col='black', diag=FALSE, mar=c(0,0,1,0))
M
?cor
ggplot(control_varImp)
control_varImp
control_varImp$Overall
colnames(control_varImp) <- c('Feature', 'Importance')
colnames(as.data.frame(control_varImp)) <- c('Feature', 'Importance')
control_varImp <- as.data.frame(control_varImp)
control_varImp
control_varImp$Overall
control_varImp <- as.data.frame(control_varImp$Overall)
control_varImp
View(control_varImp)
control_varImp$Feature <- c('GC Percentage', 'Maximum ORF Length', 'ORF Coverage', 'Maximum Occurrences of Stop Codons')
colnames(as.data.frame(control_varImp)) <- c('Feature', 'Importance')
colnames(control_varImp) <- c('Feature', 'Importance')
View(control_varImp)
colnames(control_varImp) <- c('Importance', 'Feature')
ggplot(control_varImp, aes(x = Feature, y = Importance))
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_bar()
str(control_varImp)
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col()
?geom_col
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col()
?geom_col
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col() + scale_fill_gradient(low=LtoM(100), mid='snow3', high=MtoH(100), space='Lab')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col() + scale_fill_gradient()
?scale_fill_gradient
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col() + scale_fill_gradient()
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col() + scale_fill_gradient(low='red', mid='snow3', high='darkgreen')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col() + scale_fill_gradient(low='red', high='darkgreen')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col() + scale_fill_brewer()
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(color='rainbow')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col()
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(color='pink')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(fill='blue')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(fill='cyan')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(fill='lightblue')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(fill='lightblue') + labs(title='Control: Feature Importance')
ggplot(control_varImp, aes(x = Feature, y = Importance)) + geom_col(fill='lightblue')
